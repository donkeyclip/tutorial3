/*
 * This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this
 * file, You can obtain one at https://mozilla.org/MPL/2.0/.
 */

import {
  audioContext,
  doNothing,
  getAnId,
  hasOwnProp,
} from '../../_coreUtils/helper';
import AudioNodeSet from './helpers/AudioNodeSet';
import ExtendableContextHandler from '../_kit/ExtendableContextHandler';

function _base64ToArrayBuffer(base64) {
  const binary_string = window.atob(base64);
  const len = binary_string.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binary_string.charCodeAt(i);
  }
  return bytes.buffer;
}

const datamcidRegex = /\[data(-mcid="+\w+")+\]/g;

class PubSub {
  constructor() {
    this.subscribers = [];
  }

  sub(id, method) {
    this.subscribers.push(method);
  }

  pub(argument) {
    for (let i = 0; i < this.subscribers.length; i++) {
      this.subscribers[i](argument);
    }
  }
}

/**
 * Specs:
 * AudioContext Handler keeps all the audio sources.
 * The audio sources are passed in the following format:
 * - src (the source of the sound)
 * - base64 (boolean, defaults to false. If the sound is base64 it's been treated
 *      in a different way)
 * - id (must be unique)
 * - classes (an array of belonging classes)
 *
 * The SoundContextHanlder creates a media element of the following format:
 * media: {
 *  src
 *  id
 *  classes
 *  base64
 *  buffer
 *  nodes: {
 *      stereo
 *      highpass
 *      lowpass
 *      gain
 *      audioNodeSet
 *  }
 * }
 *
 * Finally the SoundContextHandler has its own nodes (the master) which look like this:
 * master: {
 *      stereo
 *      highpass
 *      lowpass
 *      gain
 * }
 * */

class AudioContextHandler extends ExtendableContextHandler {
  constructor(audioSources = {}, masterNode) {
    super();
    // variables to be used for checking context rediness
    this.totalSources = audioSources.length;

    // initialisation of the final audio resources colleciton
    this.audioSources = {};

    // iterate on audioSource to create the audioSources collection
    for (let i = 0; i < audioSources.length; i++) {
      const audioSource = audioSources[i];
      const audioResource = {
        mcid: audioSource.mcid || getAnId(),
        id: audioSource.id,
        src: audioSource.src,
        classes: audioSource.classes || [],
        base64: audioSource.base64 || false,
        pubSub: new PubSub(),
        soundLoaded: false,
        startValues: audioSource.startValues || {},
      };

      this.audioSources[audioResource.id] = audioResource;

      this.elementsByMCID[audioResource.mcid] = audioResource;

      if (audioSource.base64) {
        audioContext.decodeAudioData(
          _base64ToArrayBuffer(audioSource.src),
          (buffer) => {
            this._setBuffer(audioResource, buffer, masterNode);
          },
        );
      } else {
        const request = new XMLHttpRequest();
        request.open('GET', audioResource.src, true);
        request.responseType = 'arraybuffer';

        // Decode asynchronously
        this.soundLoaded = false;
        request.onload = () => {
          audioContext.decodeAudioData(
            request.response,
            (buffer) => {
              this._setBuffer(audioResource, buffer, masterNode);
            },
            this.onError,
          );
        };
        request.send();
      }
    }

    this.setContext({
      contextLoaded: true,
      audio: true,
      document,
      window,
      rootElement: document.body,
      unmount: doNothing,
      masterNode,
      audioContext,
    });
  }

  _setBuffer(audioResource, buffer, masterNode) {
    audioResource.soundLoaded = true;
    audioResource.buffer = buffer;

    audioResource.audioNodeSet = new AudioNodeSet();
    audioResource.audioNodeSet.connect(masterNode.input);
    audioResource.pubSub.pub();
  }

  getElementByMCID(mcid) {
    if (hasOwnProp(this.elementsByMCID, mcid)) {
      return this.elementsByMCID[mcid];
    }

    return null;
  }

  getElements(selector) {
    if (selector.charAt(0) === '~') {
      selector = selector.substr(1);
      if (selector.charAt(0) === '#') {
        if (hasOwnProp(this.audioSources, selector.substr(1))) {
          return [this.audioSources[selector.substr(1)]];
        }

        return [];
      }
      if (selector.charAt(0) === '.') {
        const className = selector.substr(1);
        const toReturn = [];
        for (const source in this.audioSources) {
          if (source.classes.indexOf(className) >= 0) {
            toReturn.push(source);
          }
        }
        return toReturn;
      }
    } else if (datamcidRegex.exec(selector)) {
      const mcid = selector.split('"')[1];
      return this.elementsByMCID[mcid];
    } else {
      return [];
    }
  }

  getMCID(element) {
    return element.mcid;
  }

  setMCID(element, mcid) {
    element.mcid = mcid;
  }

  getElementSelectorByMCID(mcid) {
    return `[data-mcid="${mcid}"]`;
  }
}

export default AudioContextHandler;
